}
if(length(html_temp) == 0){
html_temp <- html_element(url_temp, xpath = '//p[(((count(preceding-sibling::*) + 1) = 9) and parent::*)]')
}
desc_temp <- html_text(html_temp)
desc_temp <- desc_temp %>% paste(collapse = ' ')
east_links$desc[i] <- desc_temp
}
# remove temps
rm(url_temp)
rm(desc_temp)
rm(html_temp)
trimws(east_links$desc)
head(east_links)
texts <- as_tibble(data.frame(east_links$place,east_links$desc))
library(tidytext)
library(tm)
stop_words <- stopwords("en")
stop_words + c("chicago")
stop_words <- stopwords("en")
class(stop_words)
paste0("chicago")
paste0("chicago",stop_words)
library(tidytext)
library(tm)
stop_words <- stopwords("en")
words %>% anti_join(stop_words)
library(xml2)
library(rvest)
library(tidyverse)
library(jsonlite)
library(robotstxt)
library(RSocrata)
library(dplyr)
library(tidytext)
library(tm)
link <- "https://en.wikipedia.org/wiki/Grand_Boulevard,_Chicago"
paths_allowed(link)
url <- read_html(link)
# find other links
other_places <- html_element(url, xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "navbox-odd", " " ))]//table')
# get links of other places
place_links <- other_places %>% html_nodes("a") %>% html_attr("href")%>% data.frame()
for (i in 1:dim(place_links)[1]) {
place_links[i,1] <- paste0("https://en.wikipedia.org",place_links[i,1], collapse = NULL)
}
names(place_links)[1] <- "link"
# get names of places
place_names <- other_places %>% html_nodes("a") %>% html_attr("title") %>% data.frame()
names(place_names)[1] <- "name"
place_names <- place_names %>% separate(name,c("place","city"),",")
# combine names and links
links <- cbind(place_links,place_names)
rm(place_links)
rm(place_names)
# combine all links
links[dim(links)[1]+1,] <- c("https://en.wikipedia.org/wiki/Grand_Boulevard,_Chicago","Grand Boulevard"," Chicago")
trimws(links$city)
head(links)
# scrape data
tables <- data.frame()
for (i in 1:dim(links)[1]){
url_temp <- read_html(links$link[i])
html_temp <- html_element(url_temp, xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "us-census-pop-right", " " ))]')
if(length(html_temp)==0){
html_temp <- html_element(url_temp, xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "us-census-pop-left", " " ))]')
}
table_temp <- html_table(html_temp)
table_temp$City <- links$city[i]
table_temp$Place <- links$place[i]
table_temp <- table_temp[,-3]
table_temp <- table_temp[-dim(table_temp)[1],]
tables <- rbind(tables,table_temp)
}
# change column name
names(tables)[3] <- "Changes"
names(tables)[2] <- "Pop"
# remove temps
rm(url_temp)
rm(table_temp)
rm(html_temp)
head(tables)
# clean data, turn char to number
tables$Pop <- gsub(",",'',tables$Pop)
for (i in 1:dim(tables)[1]) {
temp <- tables$Changes[i]
temp <- gsub("%",'',temp)
if(temp == "—"){
temp = as.numeric(0.00)
}else if(str_detect(temp,"−")== TRUE){
temp <- gsub("−",'',temp)
temp <- as.numeric(temp)
temp = -1*temp
temp <- temp/100
}else{
temp <- as.numeric(temp)
temp <- temp/100
}
tables$Changes[i] <- temp
}
rm(temp)
tables$Changes <- as.numeric(tables$Changes)
tables$Pop <- as.numeric(tables$Pop)
head(tables)
# I actually do this part in my second R block, but collect all places info.
# filter get east places
east <- other_places %>% html_table() %>% data.frame() %>% na.omit()
east <- subset(east, !apply(is.na(east) | east == "", 1, all))
east <- east[,-c(1,2)]
east <- gsub(", Chicago","",east)
east <- east %>% c("Grand Boulevard")
east_tables <- subset(tables, Place %in% east)
east_links <- subset(links, place %in% east)
# get description of each place
# description <- description %>% paste(collapse = ' ')
for (i in 1:dim(east_links)[1]){
url_temp <- read_html(east_links$link[i])
html_temp <- html_element(url_temp, xpath = '//p[(((count(preceding-sibling::*) + 1) = 6) and parent::*)]')
if(length(html_temp) == 0){
html_temp <- html_element(url_temp, xpath = '//p[(((count(preceding-sibling::*) + 1) = 7) and parent::*)]')
}
if(length(html_temp) == 0){
html_temp <- html_element(url_temp, xpath = '//p[(((count(preceding-sibling::*) + 1) = 8) and parent::*)]')
}
if(length(html_temp) == 0){
html_temp <- html_element(url_temp, xpath = '//p[(((count(preceding-sibling::*) + 1) = 9) and parent::*)]')
}
desc_temp <- html_text(html_temp)
desc_temp <- desc_temp %>% paste(collapse = ' ')
east_links$desc[i] <- desc_temp
}
# remove temps
rm(url_temp)
rm(desc_temp)
rm(html_temp)
trimws(east_links$desc)
head(east_links)
texts <- as_tibble(data.frame(east_links$place,east_links$desc))
stop_words <- stopwords("en")
words <- texts %>%
unnest_tokens(word, east_links.desc)
words %>% anti_join(stop_words)
words <- words %>% anti_join(stop_words)
# anti_join
data("stop_words")
words %>% anti_join(stop_words)
View(other_places)
View(stop_words)
# anti_join - remove stop words
#data("stop_words")
# words <-words %>% anti_join(stop_words)
```
# anti_join - remove stop words
#data("stop_words")
words <-words %>% anti_join(stop_words)
words %>%
count(word, sort = TRUE)
words %>% table() %>% data.frame() %>%
group_by(east_links.place) %>%
filter(Freq == max(Freq)) %>%
ggplot(aes(x = east_links.place, y = Freq, fill = word)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Most Common Words", x = "Location", y = "Frequency") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
library(ggplot2)
words %>%
count(word, sort = TRUE) %>%
filter(n > 1) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col() +
labs(y = NULL)
library(xml2)
library(rvest)
library(tidyverse)
library(jsonlite)
library(robotstxt)
library(RSocrata)
library(dplyr)
library(tidytext)
library(tm)
link <- "https://en.wikipedia.org/wiki/Grand_Boulevard,_Chicago"
paths_allowed(link)
url <- read_html(link)
# find other links
other_places <- html_element(url, xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "navbox-odd", " " ))]//table')
# get links of other places
place_links <- other_places %>% html_nodes("a") %>% html_attr("href")%>% data.frame()
for (i in 1:dim(place_links)[1]) {
place_links[i,1] <- paste0("https://en.wikipedia.org",place_links[i,1], collapse = NULL)
}
names(place_links)[1] <- "link"
# get names of places
place_names <- other_places %>% html_nodes("a") %>% html_attr("title") %>% data.frame()
names(place_names)[1] <- "name"
place_names <- place_names %>% separate(name,c("place","city"),",")
# combine names and links
links <- cbind(place_links,place_names)
rm(place_links)
rm(place_names)
# combine all links
links[dim(links)[1]+1,] <- c("https://en.wikipedia.org/wiki/Grand_Boulevard,_Chicago","Grand Boulevard"," Chicago")
trimws(links$city)
head(links)
# scrape data
tables <- data.frame()
for (i in 1:dim(links)[1]){
url_temp <- read_html(links$link[i])
html_temp <- html_element(url_temp, xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "us-census-pop-right", " " ))]')
if(length(html_temp)==0){
html_temp <- html_element(url_temp, xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "us-census-pop-left", " " ))]')
}
table_temp <- html_table(html_temp)
table_temp$City <- links$city[i]
table_temp$Place <- links$place[i]
table_temp <- table_temp[,-3]
table_temp <- table_temp[-dim(table_temp)[1],]
tables <- rbind(tables,table_temp)
}
# change column name
names(tables)[3] <- "Changes"
names(tables)[2] <- "Pop"
# remove temps
rm(url_temp)
rm(table_temp)
rm(html_temp)
head(tables)
# clean data, turn char to number
tables$Pop <- gsub(",",'',tables$Pop)
for (i in 1:dim(tables)[1]) {
temp <- tables$Changes[i]
temp <- gsub("%",'',temp)
if(temp == "—"){
temp = as.numeric(0.00)
}else if(str_detect(temp,"−")== TRUE){
temp <- gsub("−",'',temp)
temp <- as.numeric(temp)
temp = -1*temp
temp <- temp/100
}else{
temp <- as.numeric(temp)
temp <- temp/100
}
tables$Changes[i] <- temp
}
rm(temp)
tables$Changes <- as.numeric(tables$Changes)
tables$Pop <- as.numeric(tables$Pop)
head(tables)
# I actually do this part in my second R block, but collect all places info.
# filter get east places
east <- other_places %>% html_table() %>% data.frame() %>% na.omit()
east <- subset(east, !apply(is.na(east) | east == "", 1, all))
east <- east[,-c(1,2)]
east <- gsub(", Chicago","",east)
east <- east %>% c("Grand Boulevard")
east_tables <- subset(tables, Place %in% east)
east_links <- subset(links, place %in% east)
# get description of each place
# description <- description %>% paste(collapse = ' ')
for (i in 1:dim(east_links)[1]){
url_temp <- read_html(east_links$link[i])
html_temp <- html_element(url_temp, xpath = '//p[(((count(preceding-sibling::*) + 1) = 6) and parent::*)]')
if(length(html_temp) == 0){
html_temp <- html_element(url_temp, xpath = '//p[(((count(preceding-sibling::*) + 1) = 7) and parent::*)]')
}
if(length(html_temp) == 0){
html_temp <- html_element(url_temp, xpath = '//p[(((count(preceding-sibling::*) + 1) = 8) and parent::*)]')
}
if(length(html_temp) == 0){
html_temp <- html_element(url_temp, xpath = '//p[(((count(preceding-sibling::*) + 1) = 9) and parent::*)]')
}
desc_temp <- html_text(html_temp)
desc_temp <- desc_temp %>% paste(collapse = ' ')
east_links$desc[i] <- desc_temp
}
# remove temps
rm(url_temp)
rm(desc_temp)
rm(html_temp)
trimws(east_links$desc)
head(east_links)
texts <- as_tibble(data.frame(east_links$place,east_links$desc))
stop_words <- stopwords("en")
words <- texts %>%
unnest_tokens(word, east_links.desc)
words <- words %>%
filter(!(word %in% stop_words))
head(texts)
words %>%
count(word, sort = TRUE)
# anti_join - remove stop words
#data("stop_words")
words <-words %>% anti_join(stop_words)
words <- texts %>%
unnest_tokens(word, east_links.desc)
words <- words %>%
filter(!(word %in% stop_words))
head(texts)
words %>%
count(word, sort = TRUE)
words %>% table() %>% data.frame() %>%
group_by(east_links.place) %>%
filter(Freq == max(Freq)) %>%
ggplot(aes(x = east_links.place, y = Freq, fill = word)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Most Common Words", x = "Location", y = "Frequency") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
library(ggplot2)
words %>%
count(word, sort = TRUE) %>%
filter(n > 1) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col() +
labs(y = NULL)
?spotifyr
install.packages('spotifyr')
Boston %>% group_by(chas) %>% summarize(mean_crim = mean(crim), sd_crim = sd(crim))
library(dplyr)
Boston %>% group_by(chas) %>% summarize(mean_crim = mean(crim), sd_crim = sd(crim))
data("Boston")
Boston %>% group_by(chas) %>% summarize(mean_crim = mean(crim), sd_crim = sd(crim))
library(MASS)
library(faraway)
library(dplyr)
library(xml2)
library(rvest)
library(tidyverse)
library(jsonlite)
library(robotstxt)
library(RSocrata)
library(dplyr)
library(tidytext)
library(tm)
data("Boston")
Boston %>% group_by(chas) %>% summarize(mean_crim = mean(crim), sd_crim = sd(crim))
list(1)
x <- list(1)
x[[1]]
x[1]
library(dplyr)
library(ggplot2)
library(faraway)
data("teengamb")
mod1 <- lm(gamble ~ sex + status + income + verbal, teengamb)
mod1_x_star<-c(1,0,mean(teengamb$status),mean(teengamb$income),mean(teengamb$verbal))
mod1_x_star_dat<-data.frame(t(mod1_x_star))
mod1_y_star<-sum(mod1_x_star*coef(mod1))
colnames(mod1_x_star_dat)<-c("(Intercept)","sex","status","income","verbal")
predict(mod1, new=mod1_x_star_dat, interval="predict")
View(mod1_x_star_dat)
mod1_x_star1 <- c(1,0,max(teengamb$status),max(teengamb$income),max(teengamb$verbal))
mod1_x_star1_dat <- data.frame(t(mod1_x_star))
mod1_y_star1 <- sum(mod1_x_star*coef(mod1))
colnames(mod1_x_star1_dat) <- c("(Intercept)","sex","status","income","verbal")
predict(mod1, new=mod1_x_star1_dat, interval="predict")
View(mod1_x_star_dat)
View(mod1_x_star1_dat)
View(mod1_x_star_dat)
View(mod1_x_star1_dat)
View(mod1)
View(mod1_x_star1_dat)
View(mod1_x_star_dat)
View(mod1_x_star1_dat)
View(mod1_x_star_dat)
View(mod1_x_star1_dat)
mod1_x_star1 <- c(1,0,max(teengamb$status),max(teengamb$income),max(teengamb$verbal))
mod1_x_star1_dat <- data.frame(t(mod1_x_star1))
mod1_y_star1 <- sum(mod1_x_star*coef(mod1))
colnames(mod1_x_star1_dat) <- c("(Intercept)","sex","status","income","verbal")
predict(mod1, new=mod1_x_star1_dat, interval="predict")
mod2 <- lm(sqrt(gamble) ~ sex + status + income + verbal, teengamb)
mod2_x_star <- c(1 ,0 ,mean(teengamb$status), mean(teengamb$income), mean(teengamb$verbal))
mod2_x_star_dat <- data.frame(t(mod2_x_star))
mod2_y_star <- sum(mod2_x_star*coef(mod2))^2
colnames(mod2_x_star_dat) <- c("(Intercept)","sex","status","income","verbal")
predict(mod2, new=mod2_x_star_dat, interval="predict")
View(mod2_x_star_dat)
mod2 <- lm(sqrt(gamble) ~ sex + status + income + verbal, teengamb)
mod2_x_star <- c(1 ,0 ,mean(teengamb$status), mean(teengamb$income), mean(teengamb$verbal))
mod2_x_star_dat <- data.frame(t(mod2_x_star))
mod2_y_star <- sum(mod2_x_star*coef(mod2))
colnames(mod2_x_star_dat) <- c("(Intercept)","sex","status","income","verbal")
predict(mod2, new=mod2_x_star_dat, interval="predict")
mod2 <- lm(sqrt(gamble) ~ sex + status + income + verbal, teengamb)
mod2_x_star <- c(1 ,0 ,mean(teengamb$status), mean(teengamb$income), mean(teengamb$verbal))
mod2_x_star_dat <- data.frame(t(mod2_x_star))
mod2_y_star <- sum(mod2_x_star*(coef(mod2)^2))
colnames(mod2_x_star_dat) <- c("(Intercept)","sex","status","income","verbal")
predict(mod2, new=mod2_x_star_dat, interval="predict")
mod2 <- lm(sqrt(gamble) ~ sex + status + income + verbal, teengamb)
mod2_x_star <- c(1 ,0 ,mean(teengamb$status), mean(teengamb$income), mean(teengamb$verbal))
mod2_x_star_dat <- data.frame(t(mod2_x_star))
mod2_y_star <- sum(mod2_x_star*(coef(mod2)*coef(mod2)))
colnames(mod2_x_star_dat) <- c("(Intercept)","sex","status","income","verbal")
predict(mod2, new=mod2_x_star_dat, interval="predict")
View(mod2_x_star_dat)
coef(mod2)
mod2 <- lm(sqrt(gamble) ~ sex + status + income + verbal, teengamb)
mod2_x_star <- c(1 ,0 ,mean(teengamb$status), mean(teengamb$income), mean(teengamb$verbal))
mod2_x_star_dat <- data.frame(t(mod2_x_star))
mod2_y_star <- sum(mod2_x_star*coef(mod2))
colnames(mod2_x_star_dat) <- c("(Intercept)","sex","status","income","verbal")
predict(mod2, new=mod2_x_star_dat, interval="predict")
mod2 <- lm(sqrt(gamble) ~ sex + status + income + verbal, teengamb)
mod2_x_star <- c(1 ,0 ,mean(teengamb$status), mean(teengamb$income), mean(teengamb$verbal))
mod2_x_star_dat <- data.frame(t(mod2_x_star))
mod2_y_star <- sum(mod2_x_star*coef(mod2)) ^2
colnames(mod2_x_star_dat) <- c("(Intercept)","sex","status","income","verbal")
predict(mod2, new=mod2_x_star_dat, interval="predict")
mod2 <- lm(sqrt(gamble) ~ sex + status + income + verbal, teengamb)
mod2_x_star <- c(1 ,0 ,mean(teengamb$status), mean(teengamb$income), mean(teengamb$verbal))
mod2_x_star_dat <- data.frame(t(mod2_x_star))
mod2_y_star <- sum(mod2_x_star*coef(mod2))^2
mod2_y_star
colnames(mod2_x_star_dat) <- c("(Intercept)","sex","status","income","verbal")
predict(mod2, new=mod2_x_star_dat, interval="predict")
mod2_x_star1 <- c( 1, 1, 20, 1, 10)
mod2_x_star1_dat <- data.frame(t(mod2_x_star))
mod2_y_star1 <- sum(mod2_x_star1*coef(mod2))^2
mod2_y_star1
colnames(mod2_x_star1_dat) <- c("(Intercept)","sex","status","income","verbal")
predict(mod2, new=mod2_x_star1_dat, interval="predict")
mod2_x_star1 <- c( 1, 1, 20, 1, 10)
mod2_x_star1_dat <- data.frame(t(mod2_x_star1))
mod2_y_star1 <- sum(mod2_x_star1*coef(mod2))^2
mod2_y_star1
colnames(mod2_x_star1_dat) <- c("(Intercept)","sex","status","income","verbal")
predict(mod2, new=mod2_x_star1_dat, interval="predict")
mod1_x_star <- c(1,0,mean(teengamb$status),mean(teengamb$income),mean(teengamb$verbal))
mod1_x_star_dat <- data.frame(t(mod1_x_star))
mod1_y_star <- sum(mod1_x_star*coef(mod1))
colnames(mod1_x_star_dat) <- c("(Intercept)","sex","status","income","verbal")
predict(mod1, new=mod1_x_star_dat, interval="confidence")
mod1_x_star <- c(1,0,mean(teengamb$status),mean(teengamb$income),mean(teengamb$verbal))
mod1_x_star_dat <- data.frame(t(mod1_x_star))
mod1_y_star <- sum(mod1_x_star*coef(mod1))
colnames(mod1_x_star_dat) <- c("(Intercept)","sex","status","income","verbal")
predict(mod1, new=mod1_x_star_dat, interval="confidence")
round(mod2_y_star,2)
knitr::opts_chunk$set(echo=TRUE,cache=TRUE,
autodep=TRUE, cache.comments=FALSE,
message=FALSE, warning=FALSE,
fig.width=4.5, fig.height=3)
library(dplyr)
library(ggplot2)
library(faraway)
data("teengamb")
library(dplyr)
library(ggplot2)
library(faraway)
data("teengamb")
library(dplyr)
library(ggplot2)
library(faraway)
data("teengamb")
mod1 <- lm(gamble ~ sex + status + income + verbal, teengamb)
mod1_x_star <- c(1,0,mean(teengamb$status),mean(teengamb$income),mean(teengamb$verbal))
mod1_x_star_dat <- data.frame(t(mod1_x_star))
mod1_y_star <- sum(mod1_x_star*coef(mod1))
colnames(mod1_x_star_dat) <- c("(Intercept)","sex","status","income","verbal")
predict(mod1, new=mod1_x_star_dat, interval="predict")
mod1_y_star
View(teengamb)
?apply
apply(teengamb,2,mean)
#| include: false
library(tidyverse)
library(DBI)
library(dbplyr)
library(bigrquery)
library(magrittr)
project <- "surv-727-test-403117"
con <- dbConnect(
bigrquery::bigquery(),
project = "bigquery-public-data",
dataset = "chicago_crime",
billing = project
)
con
dbListTables(con)
query <- "SELECT date, count(*) counts_date FROM crime WHERE date >= '2016-01-01 00:00:00' and date <= '2017-01-01 00:00:00' group by date;"
count_date_2016 <- dbGetQuery(con, query)
count_date_2016$date <- as.character(count_date_2016$date)
count_date_2016 %<>%
separate(date, c("date","time"), sep = " ")
count_date_2016 <- count_date_2016[,-1]
count_date_2016 <- aggregate(counts_date ~ time, data = count_date_2016, sum)
count_date_2016 %>% subset(counts_date==max(count_date_2016$counts_date))
query <- "SELECT primary_type, count(*) counts FROM crime WHERE date >= '2016-01-01 00:00:00' and date <= '2017-01-01 00:00:00' and district = 11 group by primary_type order by counts DESC LIMIT 10;"
dbGetQuery(con,query)
crime <- tbl(con, "crime")
crime %>% filter(district == 11, date >= '2016-01-01 00:00:00' && date <= '2017-01-01 00:00:00')%>% group_by(primary_type) %>% count(primary_type)
crime %>% filter(district == 11)%>% group_by(primary_type)
#%>% count(primary_type) %>% group_by(year)
crime %>% filter(district == 11)%>% group_by(primary_type) %>% count(primary_type) #%>% group_by(year)
crime %>% filter(district == 11)%>% group_by(primary_type, year)# %>% count(primary_type) #%>% group_by(year)
crime %>% filter(district == 11)%>% group_by(primary_type, year) %>% order_by(year) #%>% group_by(year)
crime %>% filter(district == 11)%>% group_by(primary_type, year) %>% arrange(year) #%>% group_by(year)
crime %>% filter(district == 11) %>% group_by(year, primary_type) %>%   summarize(arrest_count = n())
crime %>% filter(district == 11) %>% group_by(year, primary_type) %>%   summarize(arrest_count = n()) %>% arrange(year)
year_primary <- crime %>% filter(district == 11) %>% group_by(year, primary_type) %>%   summarize(arrest_count = n()) %>% arrange(year)
year_primary[1:10,]
year_primary[c(1:10),]
year_primary[,c(1:10)]
View(year_primary)
year_primary <- crime %>% filter(district == 11) %>% group_by(year, primary_type) %>%   summarize(arrest_count = n()) %>% arrange(year) %>% data.frame()
View(year_primary)
year_primary[c(1:10),]
